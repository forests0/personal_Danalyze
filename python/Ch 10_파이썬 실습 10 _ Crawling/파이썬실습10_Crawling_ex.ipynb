{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"파이썬실습10_Crawling_ex.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOXpRD+xLDPVHEFghOZ6BDL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UVFGkDd1kwHn"},"source":["#Crawling  \n","크롤링이란?: 소프트웨어를 사용해 웹상에서 정보를 찾아 특정 데이터베이스로 수집해 오는 작업 또는 기술."]},{"cell_type":"markdown","metadata":{"id":"ZfQ9TYMYQzV2"},"source":["##1.BeautifulSoup  \n","BeautifulSoup란? : 복잡한 웹페이지를 스크래핑하기 쉽도록 단순한 구조로 만들어주는 파이썬 라이브러리"]},{"cell_type":"markdown","metadata":{"id":"2xyKSJSUTrwP"},"source":["###1-1. BeautifulSoup로 웹페이지 긁어오기"]},{"cell_type":"code","metadata":{"id":"7gpIEzMfQ6YP"},"source":["import _________\n","from ___ import ________________"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjL7IJ2pRhbV"},"source":["#BeautifulSoup 이용해서 당근마켓 페이지에 있는 내용 모두 긁어오기\n","webpage = ______.___(\"_\")\n","soup = ____________(______.______, \"____________\")\n","print(soup)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gS8tyglESKnT"},"source":["#html에 대해 전부 다 이해할 필요는 없다\n","#구조를 보면 <> 안에 class로 나뉘어져 있는 것이 html의 구조\n","print(____._)\n","#태그 빼고 글만 보기\n","print('')\n","print(____._.______)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-Onz7l_S92t"},"source":["#p class만 따로 뽑아서 보기\n","print(soup._________('_'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qb21nJwXWgNx"},"source":["###1-2. 네이버 기사제목 긁어오기"]},{"cell_type":"code","metadata":{"id":"dLk-P-pwWflj"},"source":["#뉴스 기사 검색 키워드\n","keyword = '_'\n","url = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}' #네이버 뉴스기사 포맷을 보자"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILTpibRjXE7S"},"source":["#키워드 검색하고 페이지 긁어오기\n","#a tag 만 모아서 보자\n","news = ________.___(___)\n","soup = _____________(news.______, 'html.parser')\n","print(soup)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N96vOJedkL7u"},"source":["a = soup.________('_')\n","a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-2JyH_wa8wn"},"source":["#a tag 아래에 .news_tit 이라는 클래스가 뉴스 제목임을 알 수 있다\n","titles = soup.______('_______')\n","titles"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SV3qUaZXJki"},"source":["print(len(titles), '개의 뉴스가 검색되었습니다')\n","print('')\n","for ______ in ______:\n","    print(______['______'])\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PxYqpeuNTkP5"},"source":["##2.Selenium"]},{"cell_type":"markdown","metadata":{"id":"Vu9uSE35plRT"},"source":["###1-1. Selenium 설치하기"]},{"cell_type":"code","metadata":{"id":"JnE8ULTgdln_"},"source":["#Selenium 설치하기\n","!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X7W8Au59rJxo"},"source":["이후 단계 진행은 Jupyter Notebook 에서 하겠습니다."]}]}